# Prompt_Learning_Paper_List 



## Review and Survey Paper 
* **Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing**, Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, Graham Neubig, 
[[Paper](https://arxiv.org/abs/2107.13586)]
[[Project](http://pretrain.nlpedia.ai/)]
[[Github](https://github.com/pfliu-nlp/NLPedia-Pretrain)]

 


## Year 2022 


* **Understanding and Mitigating Overfitting in Prompt Tuning for Vision-Language Models**, Chengcheng Ma et al. 
[[Paper](https://arxiv.org/pdf/2211.02219.pdf)] 
[[Code](https://tinyurl.com/mpe64f89)]


* **Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models**, 
[[Paper](https://arxiv.org/pdf/2209.07511.pdf)] 
[[Project](https://azshue.github.io/TPT/)]
[[Code](https://github.com/azshue/TPT)]

* **Z-LaVI: Zero-Shot Language Solver Fueled by Visual Imagination**, Yue Yang et al. 
[[Paper](https://arxiv.org/pdf/2210.12261.pdf)]
[[Code](https://github.com/YueYANG1996/Z-LaVI)]


* **A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models**, 
[[Paper](https://arxiv.org/abs/2110.08484)] 
[[Code](https://github.com/woojeongjin/FewVLM)] 


* **CLIP-Adapter: Better Vision-Language Models with Feature Adapters**, 
[[Paper](https://arxiv.org/pdf/2110.04544.pdf)]
[[Code](https://github.com/gaopengcuhk/CLIP-Adapter)]


* **Prompting through Prototype: A Prototype-based Prompt Learning on Pretrained Vision-Language Models**, 
[[Paper](https://arxiv.org/pdf/2210.10841.pdf)]



## Year 2021 





## Year 2020 




## Year 2019 



